{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "556e7862-c59b-a1e7-c8d2-91bcd7dc5b8c"
   },
   "source": [
    "Aim: Predict Rating from Review using basic and deep models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4d6a2d9e-f548-ceaf-9226-97d0ef00023c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "english_stemmer=nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from abc import ABCMeta\n",
    "from scipy import sparse\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.preprocessing import normalize, binarize, LabelBinarizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import defaultdict\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras import backend as K\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "3764b93f-8c69-a9c2-d40a-70f164032661"
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "daf69378-7811-49c3-1b1c-b28aad12ad91"
   },
   "source": [
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2688fc8f-ca7b-9bd7-bc6e-8ea18ebdb957"
   },
   "source": [
    "Here is the process :\n",
    "* Remove the non Letters\n",
    "* Convert everything to lower case\n",
    "* Remove stop words\n",
    "* Stem the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "68c37e32-789d-1ecf-d88f-679cd79fe461"
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=True):\n",
    "    # Data Pre-processing\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "\n",
    "    #\n",
    "    # 1. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    #\n",
    "    # 2. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 3. Optionally remove stop words (True by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(['those', 'ourselves', 'off', 'only', 'other', 'very', \\\n",
    "            're', 'over', 'should', 'mightn', 'then', 'where', 'some', 'aren', \\\n",
    "            'to', 'couldn', 'theirs', 'mustn', 'our', 'did', 'before', \\\n",
    "            'himself', 'her', 'needn', \"aren't\", 'him', 'she', 'he', 'through',\\\n",
    "            'shan', 'by', 'into', \"didn't\", 'myself', \"should've\", \"wouldn't\",\\\n",
    "            'if', 'they', 'same', 'wouldn', 'am', 'its', 'which', 'each',\\\n",
    "            'under', 'is', 'once', 'a', 'out', 'few', 'all', 'do', 'haven',\\\n",
    "            'an', 'yours', 'while', 'both', 've', 'what', 'ain', 'herself',\\\n",
    "            'themselves', 'for', 'will', 'have', \"mustn't\", 'more', 'that',\\\n",
    "            'ours', 'hers', 'doesn', 'no', 'your', 'just', 'below', 'll','isn',\\\n",
    "            'has', \"don't\", 'does', 'don', 'can', 'won', 'in', 'than', 'were',\\\n",
    "            'didn', \"mightn't\", \"wasn't\", 'd', 'against', 'most', 'been',\\\n",
    "            'during', \"shan't\", 'this', 'on', 'weren', 'hasn', 'up', 'be',\\\n",
    "            \"it's\", 'shouldn', 'these', 'so', 'because', 'm', \"isn't\",\\\n",
    "            \"doesn't\", 'here', 'and', 'we', 'between', 'itself', 'doing','you',\\\n",
    "            \"haven't\", 'his', 'after', 'as', 'until', 'own', \"shouldn't\",\\\n",
    "            'above', 'or', 'who', 'why', 'nor', 'it', 'again', 'yourselves',\\\n",
    "            'their', \"that'll\", \"couldn't\", \"you're\", 'how', 'my', 'down', 'o',\\\n",
    "            'me', 'further', 'whom', 'of', \"you'll\", \"hasn't\", 'being', 'i',\\\n",
    "            'now', 'at', 'the', \"hadn't\", 'wasn', 'with', 'ma', 'had',\\\n",
    "            \"needn't\", 'having', \"you'd\", 'there', \"you've\", 't',\\\n",
    "            'about', 'any', 'such', 'are', \"won't\", 'y', 'hadn', 'yourself',\\\n",
    "            's', 'was', 'but', 'too', \"she's\", \"weren't\", 'when', 'from', 'them'])\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    b=[]\n",
    "    stemmer = english_stemmer #PorterStemmer()\n",
    "    for word in words:\n",
    "        b.append(stemmer.stem(word))\n",
    "\n",
    "    # 4. Return a list of words\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a43527ec-5612-afeb-ffdd-3b823b676e72"
   },
   "source": [
    "## Import Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "51e77b0c-7cd7-6ba0-53e7-c126d6ea2d6f"
   },
   "source": [
    "We import only 20000 lines of our total data in order to run the notebook faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "a741e1fc-0191-c6f4-f476-52d494d17698"
   },
   "outputs": [],
   "source": [
    "data_file = '~/Downloads/Amazon_Unlocked_Mobile.csv'\n",
    "\n",
    "n = 413000  \n",
    "s = 20000 # 20000 \n",
    "skip = sorted(random.sample(range(1,n),n-s))\n",
    "\n",
    "data = pd.read_csv( data_file, delimiter = \",\", skiprows = skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>2</td>\n",
       "      <td>Phone looks good but wouldn't stay charged, ha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Just got this phone and it is a great phone. I...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[XMAS DEAL] [New Edition] Jethro [SC213V2] Fli...</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>79.99</td>\n",
       "      <td>5</td>\n",
       "      <td>This phone was purchased for my father. I real...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[XMAS DEAL] [New Edition] Jethro [SC213V2] Fli...</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>79.99</td>\n",
       "      <td>2</td>\n",
       "      <td>the phone is unable to maintain signal after 2...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>59.99</td>\n",
       "      <td>2</td>\n",
       "      <td>sound quality poor, no speaker phone</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>59.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>59.99</td>\n",
       "      <td>5</td>\n",
       "      <td>With a little bit of effort I was able to fami...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>59.99</td>\n",
       "      <td>2</td>\n",
       "      <td>We bought the phone for my 92 year old mother ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...</td>\n",
       "      <td>Jethro</td>\n",
       "      <td>59.99</td>\n",
       "      <td>5</td>\n",
       "      <td>It's just what we were looking for</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.6'' Inch E-passion Unlocked Smart Phone +Ta...</td>\n",
       "      <td>e passion</td>\n",
       "      <td>99.95</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is not worth the money I paid. cant ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  [XMAS DEAL] [New Edition] Jethro [SC213V2] Fli...     Jethro   79.99   \n",
       "3  [XMAS DEAL] [New Edition] Jethro [SC213V2] Fli...     Jethro   79.99   \n",
       "4  [XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...     Jethro   59.99   \n",
       "5  [XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...     Jethro   59.99   \n",
       "6  [XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...     Jethro   59.99   \n",
       "7  [XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...     Jethro   59.99   \n",
       "8  [XMAS DEAL] Jethro [SC118] Simple Unlocked Qua...     Jethro   59.99   \n",
       "9  10.6'' Inch E-passion Unlocked Smart Phone +Ta...  e passion   99.95   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       2  Phone looks good but wouldn't stay charged, ha...           0.0  \n",
       "1       5  Just got this phone and it is a great phone. I...           0.0  \n",
       "2       5  This phone was purchased for my father. I real...          15.0  \n",
       "3       2  the phone is unable to maintain signal after 2...           1.0  \n",
       "4       2               sound quality poor, no speaker phone           0.0  \n",
       "5       5                                          Thank you           1.0  \n",
       "6       5  With a little bit of effort I was able to fami...          11.0  \n",
       "7       2  We bought the phone for my 92 year old mother ...           0.0  \n",
       "8       5                 It's just what we were looking for           1.0  \n",
       "9       1  This item is not worth the money I paid. cant ...           1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "data = data.drop(columns=['Product Name', 'Brand Name', 'Price', 'Review Votes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "cd77f712-e27a-a5c3-2892-bd8b1c2a3106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20839, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Phone looks good but wouldn't stay charged, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Just got this phone and it is a great phone. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This phone was purchased for my father. I real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the phone is unable to maintain signal after 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>sound quality poor, no speaker phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>With a little bit of effort I was able to fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>We bought the phone for my 92 year old mother ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>It's just what we were looking for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>This item is not worth the money I paid. cant ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Reviews\n",
       "0       0  Phone looks good but wouldn't stay charged, ha...\n",
       "1       1  Just got this phone and it is a great phone. I...\n",
       "2       1  This phone was purchased for my father. I real...\n",
       "3       0  the phone is unable to maintain signal after 2...\n",
       "4       0               sound quality poor, no speaker phone\n",
       "5       1                                          Thank you\n",
       "6       1  With a little bit of effort I was able to fami...\n",
       "7       0  We bought the phone for my 92 year old mother ...\n",
       "8       1                 It's just what we were looking for\n",
       "9       0  This item is not worth the money I paid. cant ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['Reviews'].isnull()==False]\n",
    "\n",
    "def partition(x):\n",
    "    if x < 4:\n",
    "        return 0 # 'negative'\n",
    "    return 1 # 'positive'\n",
    "\n",
    "data['Rating'] = data['Rating'].map(partition)\n",
    "\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "a4b9503f-8820-40f2-31e3-a016d155bc2b"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d263bb83-4cf3-4f86-d30d-38902e140f30"
   },
   "source": [
    "## Labels Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "075d9e7c-236b-e7bf-d374-971404c9bd18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11655d5f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1039e1cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ba1cbbaf-2581-18c9-71bd-244c82d504b3"
   },
   "source": [
    "Much More 5 than others ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de5cb5a7-d4cd-9854-d479-4d1bb5ab7e71"
   },
   "source": [
    "### Apply Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "0d7df42d-fc16-a8d0-2ac9-36ef7eca2a97"
   },
   "outputs": [],
   "source": [
    "clean_train_reviews = []\n",
    "for review in train['Reviews']:\n",
    "    clean_train_reviews.append( \" \".join(review_to_wordlist(review)))\n",
    "\n",
    "clean_test_reviews = []\n",
    "for review in test['Reviews']:\n",
    "    clean_test_reviews.append( \" \".join(review_to_wordlist(review)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "615da5fd-a050-83f4-41c7-179d2e6d9af6"
   },
   "source": [
    "## TFidf transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8b8b704d-3214-9422-13fd-275128b1155f"
   },
   "source": [
    "### TFidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b6ed9c5d-ebd9-0a56-aeeb-3cab6ec2568a"
   },
   "source": [
    "We will use tfidf transformation with ngrams between 1 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "ec98d8dc-f48e-4c28-15d1-d37a7e84a1cc"
   },
   "outputs": [],
   "source": [
    "# Why we use sublinear_tf(replacing tf with 1 + log(tf))\n",
    "# Problem : It seems unlikely that twenty occurrences of a term in a document truly carry\n",
    "# twenty times the significance of a single occurrence\n",
    "# Reference : https://nlp.stanford.edu/IR-book/html/htmledition/sublinear-tf-scaling-1.html\n",
    "vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 200000, ngram_range = ( 1, 4 ),\n",
    "                              sublinear_tf = True )\n",
    "\n",
    "vectorizer = vectorizer.fit(clean_train_reviews)\n",
    "train_features = vectorizer.transform(clean_train_reviews)\n",
    "\n",
    "test_features = vectorizer.transform(clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape :  (14587, 76959)\n",
      "test_features.shape :  (6252, 76959)\n",
      "  (0, 76374)\t0.0960108835144\n",
      "  (0, 76243)\t0.0543412995744\n",
      "  (0, 76232)\t0.0760865590772\n",
      "  (0, 76018)\t0.0745063418633\n",
      "  (0, 73139)\t0.099012582053\n",
      "  (0, 73136)\t0.10369237326\n",
      "  (0, 72832)\t0.0545845292994\n",
      "  (0, 72628)\t0.0960108835144\n",
      "  (0, 72588)\t0.0864502302302\n",
      "  (0, 72493)\t0.0683504122605\n",
      "  (0, 70353)\t0.0917802270397\n",
      "  (0, 70345)\t0.0525760746984\n",
      "  (0, 70087)\t0.0472786081809\n",
      "  (0, 69644)\t0.0638779388487\n",
      "  (0, 69553)\t0.0627426808098\n",
      "  (0, 68922)\t0.0936825852434\n",
      "  (0, 68913)\t0.071230920439\n",
      "  (0, 68603)\t0.0429103929817\n",
      "  (0, 68176)\t0.0568882478589\n",
      "  (0, 67228)\t0.143151991144\n",
      "  (0, 67214)\t0.102920790471\n",
      "  (0, 67002)\t0.0487454518814\n",
      "  (0, 63853)\t0.0936825852434\n",
      "  (0, 63847)\t0.0991302829911\n",
      "  (0, 63405)\t0.0917802270397\n",
      "  :\t:\n",
      "  (14586, 20951)\t0.144700331349\n",
      "  (14586, 20950)\t0.126165440364\n",
      "  (14586, 20938)\t0.0619014249669\n",
      "  (14586, 19347)\t0.0943997279374\n",
      "  (14586, 14935)\t0.113015056229\n",
      "  (14586, 14929)\t0.058980248878\n",
      "  (14586, 13764)\t0.0939255575677\n",
      "  (14586, 10522)\t0.144700331349\n",
      "  (14586, 10520)\t0.115882146421\n",
      "  (14586, 9355)\t0.144700331349\n",
      "  (14586, 9167)\t0.0581744819361\n",
      "  (14586, 6887)\t0.149224264025\n",
      "  (14586, 6867)\t0.0556204002355\n",
      "  (14586, 6500)\t0.116524091027\n",
      "  (14586, 5574)\t0.113548173695\n",
      "  (14586, 5062)\t0.117892384881\n",
      "  (14586, 5043)\t0.0921601026994\n",
      "  (14586, 4860)\t0.0520515210297\n",
      "  (14586, 4314)\t0.102648116029\n",
      "  (14586, 4141)\t0.0602263076882\n",
      "  (14586, 2996)\t0.126165440364\n",
      "  (14586, 2763)\t0.0622506657157\n",
      "  (14586, 1011)\t0.149224264025\n",
      "  (14586, 981)\t0.0824897876901\n",
      "  (14586, 812)\t0.226543556145\n"
     ]
    }
   ],
   "source": [
    "print(\"train_features.shape : \", train_features.shape)\n",
    "print(\"test_features.shape : \", test_features.shape)\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6711f545-9784-2e77-4a7a-58af16519096"
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dbb07555-21c1-aa73-822e-04b7ad761b94"
   },
   "source": [
    "The forward pass of a RNN is the same as the one of a MLP except that outputs from hidden layers are also used as inputs from the same layer. That means that the input from the hidden layer is both the outputs from the hidden layer one step back in time and the external input. So we have the equation:\n",
    "\n",
    "\n",
    "\\begin{equation} \n",
    "a_{h,t} = \\sum_{i}{w_{i,h}*x_{i,t}} + \\sum_{h'}{w_{h',h}*b_{h',t-1}} \n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation} \n",
    "b_{h,t} = \\phi_{h}(a_{h,t}) \n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "where: \n",
    "* $x_{t,i} =$ value of input i at time t \n",
    "* $a_{t,j} =$ network input to unit j at time t \n",
    "* $b_{t,j}=$ output of activation of unit j at time t\n",
    "* $w_{i,h} =$  weights of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b00f06a3-eae9-b00c-df17-6c84b7990105"
   },
   "source": [
    "Long Short Term Memory networks – usually just called LSTM – are a special kind of RNN, capable of learning long-term dependencies. (The idea behind those is to counter the vanishing problem of some basic RNN.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a45e658b-9a42-9ac9-20ca-d568988e2df4"
   },
   "source": [
    "Thus, LSTM can be very usefull in text mining problems since it involves dependencies in the sentences which can be caught in the \"memory\" of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "09ec7a73-b091-92e3-a24f-77a28c18dd31"
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2\n",
    "maxlen = 30\n",
    "batch_size = 32\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "f28a2622-6859-41e9-f98d-aec9098962e2"
   },
   "outputs": [],
   "source": [
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train['Reviews'])\n",
    "sequences_train = tokenizer.texts_to_sequences(train['Reviews'])\n",
    "sequences_test = tokenizer.texts_to_sequences(test['Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "c9405324-f068-a1b2-fc63-dd98a4d3a82f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (14587, 80)\n",
      "X_test shape: (6252, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n",
    "\n",
    "y_train = np.array(train['Rating'])\n",
    "y_test = np.array(test['Rating'])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 23, 5, 12, 1887, 11, 1, 3128, 479, 4, 430, 198, 448, 1802, 1940, 443, 20, 120, 7, 105, 6, 1708, 35, 129, 37, 20, 85, 143, 7, 1033, 3, 4, 764, 7, 644, 1599, 32, 30, 7, 96, 587, 2797, 122, 4656, 1709, 7, 663, 14, 956, 587, 6469, 736, 83, 46, 2, 5350, 7, 316, 10, 1, 663, 2, 27, 7, 147, 293, 563, 5, 6470, 7, 506, 214, 28, 228, 229, 7, 318, 3, 6, 337, 494, 1, 205, 17, 2, 2675, 6, 5351, 1438, 730, 179, 48, 13, 29, 8727, 16, 129, 179, 495, 297, 1, 638, 16, 1223, 1546, 73, 1, 833, 1101, 691, 2489, 84, 105, 9, 172, 376, 12, 1, 329, 108, 1062, 8728, 268, 36, 4657, 14, 8729, 7, 122, 70, 2, 51, 8730, 283, 39, 173, 1326, 406, 32, 1350, 61, 9, 8731, 8, 13, 1710, 2, 48, 150, 21, 104, 4164, 663, 139, 32, 42, 284, 1160, 57, 48, 40, 21, 1709, 7, 393, 3, 293, 1, 287, 79, 2, 639, 834, 20, 52, 1372, 1, 136, 194, 92, 542, 1845, 4, 3556, 2956, 7, 455, 1250, 2, 40, 140, 283, 173, 342, 212, 1063, 5352, 1642, 563, 5, 6470, 21, 84, 1709, 7, 480, 1, 329, 108, 10, 2798, 11, 1761, 76, 6471, 34, 2, 21, 89, 84, 104, 16, 1941, 542, 12, 122, 4, 1297, 7, 316, 10, 1, 8732, 3, 49, 41, 6, 785, 1064, 122, 3557, 19, 5353, 17, 1, 5, 8, 42, 410, 342, 4, 49, 255, 362, 463, 1277, 52, 29, 1846, 2, 820, 6, 8733, 4, 4658, 6, 804, 32, 1, 1, 1464, 6472, 8734, 10, 1, 1887, 11, 8735, 75, 731, 491, 262, 519]\n",
      "[[1709    7  480 ...,  491  262  519]\n",
      " [   0    0    0 ...,  123   25   23]\n",
      " [   0    0    0 ...,    0  108  527]\n",
      " ..., \n",
      " [   0    0    0 ...,   13   14  129]\n",
      " [  23  609   10 ...,    6  277  230]\n",
      " [ 122   17 4090 ...,    6   23    5]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences_train[0])\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e908847-9bcb-cf94-9805-0c25bb3f5b08"
   },
   "source": [
    "The embedding layer in text mining is really important. Indeed, it is a way to map our text input into a space (a dictionary of dimension here 128). The layer is trained through iterations (epochs) to have a better weights for the dictionary that allow to minimize the global error of the network.\n",
    "\n",
    "Skip-gram, CBOW, and GloVe (or any other word2vec variant) are pre-trained word embeddings which can be set as the weight of an embedding layer. If the weight of this layer (generally the first layer of the network) is not initialized by these pre-trained vectors, the model/network itself would assign random weights and will learn the embeddings (i.e. weights) on the fly.\n",
    "\n",
    "Explanation summarized from :\n",
    "https://github.com/fchollet/keras/issues/3110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "36d3d256-4fa8-5664-a716-61e7af263220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 14587 samples, validate on 6252 samples\n",
      "Epoch 1/20\n",
      "14587/14587 [==============================] - 86s 6ms/step - loss: 0.6007 - acc: 0.6804 - val_loss: 0.5615 - val_acc: 0.6991\n",
      "Epoch 2/20\n",
      "14587/14587 [==============================] - 82s 6ms/step - loss: 0.5720 - acc: 0.6891 - val_loss: 0.5450 - val_acc: 0.7422\n",
      "Epoch 3/20\n",
      "14587/14587 [==============================] - 80s 5ms/step - loss: 0.5336 - acc: 0.7281 - val_loss: 0.4836 - val_acc: 0.7410\n",
      "Epoch 4/20\n",
      "14587/14587 [==============================] - 82s 6ms/step - loss: 0.4797 - acc: 0.7683 - val_loss: 0.4242 - val_acc: 0.8217\n",
      "Epoch 5/20\n",
      "14587/14587 [==============================] - 81s 6ms/step - loss: 0.4308 - acc: 0.8041 - val_loss: 0.3810 - val_acc: 0.8353\n",
      "Epoch 6/20\n",
      "14587/14587 [==============================] - 83s 6ms/step - loss: 0.3983 - acc: 0.8215 - val_loss: 0.3508 - val_acc: 0.8581\n",
      "Epoch 7/20\n",
      "14587/14587 [==============================] - 84s 6ms/step - loss: 0.3727 - acc: 0.8403 - val_loss: 0.3351 - val_acc: 0.8628\n",
      "Epoch 8/20\n",
      "14587/14587 [==============================] - 79s 5ms/step - loss: 0.3613 - acc: 0.8430 - val_loss: 0.3267 - val_acc: 0.8651\n",
      "Epoch 9/20\n",
      "14587/14587 [==============================] - 84s 6ms/step - loss: 0.3495 - acc: 0.8548 - val_loss: 0.3267 - val_acc: 0.8633\n",
      "Epoch 10/20\n",
      "14587/14587 [==============================] - 83s 6ms/step - loss: 0.3378 - acc: 0.8621 - val_loss: 0.3242 - val_acc: 0.8648\n",
      "Epoch 11/20\n",
      "14587/14587 [==============================] - 87s 6ms/step - loss: 0.3211 - acc: 0.8680 - val_loss: 0.3483 - val_acc: 0.8518\n",
      "Epoch 12/20\n",
      "14587/14587 [==============================] - 79s 5ms/step - loss: 0.3177 - acc: 0.8710 - val_loss: 0.3125 - val_acc: 0.8727\n",
      "Epoch 13/20\n",
      "14587/14587 [==============================] - 76s 5ms/step - loss: 0.3077 - acc: 0.8770 - val_loss: 0.3233 - val_acc: 0.8624\n",
      "Epoch 14/20\n",
      "14587/14587 [==============================] - 80s 6ms/step - loss: 0.3017 - acc: 0.8765 - val_loss: 0.3576 - val_acc: 0.8600\n",
      "Epoch 15/20\n",
      "14587/14587 [==============================] - 80s 5ms/step - loss: 0.3194 - acc: 0.8657 - val_loss: 0.3147 - val_acc: 0.8699\n",
      "Epoch 16/20\n",
      "14587/14587 [==============================] - 78s 5ms/step - loss: 0.3014 - acc: 0.8781 - val_loss: 0.3028 - val_acc: 0.8769\n",
      "Epoch 17/20\n",
      "14587/14587 [==============================] - 76s 5ms/step - loss: 0.3059 - acc: 0.8761 - val_loss: 0.5834 - val_acc: 0.6952\n",
      "Epoch 18/20\n",
      "14587/14587 [==============================] - 78s 5ms/step - loss: 0.3114 - acc: 0.8733 - val_loss: 0.3895 - val_acc: 0.8218\n",
      "Epoch 19/20\n",
      "14587/14587 [==============================] - 80s 5ms/step - loss: 0.2800 - acc: 0.8895 - val_loss: 0.2892 - val_acc: 0.8873\n",
      "Epoch 20/20\n",
      "14587/14587 [==============================] - 86s 6ms/step - loss: 0.2659 - acc: 0.8979 - val_loss: 0.2888 - val_acc: 0.8848\n",
      "6252/6252 [==============================] - 6s 944us/step\n",
      "Test loss: 0.288813297451\n",
      "Test accuracy: 0.884756877837\n",
      "Generating test predictions...\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SpatialDropout1D\n",
    "from keras import optimizers\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(SpatialDropout1D(rate=0.2))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.10)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(X_test, Y_test))\n",
    "loss, acc = model.evaluate(X_test, Y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "\n",
    "print(\"Generating test predictions...\")\n",
    "preds = model.predict_classes(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "a5d0507c-d01c-11e3-70b0-ae5a790bea26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 7 accuracy:  0.894113883557\n"
     ]
    }
   ],
   "source": [
    "print('prediction 7 accuracy: ', accuracy_score(test['Rating'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5468eeeb-e44b-925e-c70b-0f29e9d70f6b"
   },
   "source": [
    "Add epochs and reviews to be more accurate with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('./review.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1709    7  480 ...,  491  262  519]\n",
      " [   0    0    0 ...,  123   25   23]\n",
      " [   0    0    0 ...,    0  108  527]\n",
      " ..., \n",
      " [   0    0    0 ...,   13   14  129]\n",
      " [  23  609   10 ...,    6  277  230]\n",
      " [ 122   17 4090 ...,    6   23    5]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.93779212  0.06441101]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict(X_train[0:1])\n",
    "y_class = np.argmax(y_prob, axis=1)\n",
    "print(y_prob)\n",
    "print(y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80)\n",
      "[[1709    7  480 ...,  491  262  519]\n",
      " [   0    0    0 ...,  123   25   23]\n",
      " [   0    0    0 ...,    0  108  527]\n",
      " ..., \n",
      " [   0    0    0 ...,   13   14  129]\n",
      " [  23  609   10 ...,    6  277  230]\n",
      " [ 122   17 4090 ...,    6   23    5]]\n",
      "(14587, 80)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:1].shape)\n",
    "print(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
